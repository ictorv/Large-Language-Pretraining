## Causal Attention

- Causal Attention is also known as masked attention is a special form of self attention.

- It is restricts the model to only consider previous and current inputs in a sequence, when processing any given token

- When computing attention score, the causal attention mechanism ensures that the model only factors in token occur at or before the current token in the sequence.

- To achieve this in GPT like LLMs for each token processed, we mask out the future tokens, which come after the current token in the input text.

    <img src="assets/16. Causal Attention/mask.png" width="500" />   

We mask out the attention weightd above the diagonal, and we normalize the non masked attention weights,sum upto 1 in each row.

## Apply Causal Attention Mask
**Strategy**
    
<img src="assets/16. Causal Attention/strategy.png" width="500" />   

