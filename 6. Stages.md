<img src="assets/6. Steps/step.png" width="500" />    

## Stage I | Building an LLM 
Understand basic Mechanism
- Data preperation and Sampling
    - `Tokenization` : Break sentence into token
    - `Vector Embeddings` : Capture sementic meaning + Positional Encoding
    - Construct data into batches
- Attention Mechanism
    - What does Mean and different types
- LLM Architecture

## Stage II | Pretraining | Foundational Model
Pretrain on unlabeled data
- Training Loop
- Model Evaluation
- Load pretrained weights

<img src="assets/6. Steps/stage.png" width="500" />    

## Stage III | Finetuning
- Classifier
- Personal Assistant

