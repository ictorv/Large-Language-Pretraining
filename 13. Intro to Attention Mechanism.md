# Intro to Attention Mechanism

## Why Attention Mechanism?
> "The `cat` that was `sitting` on the mat,  
which was next to the dog, `jumped.`"

There are some words related to `cat` to which it LLM should pay attention in order to understand about `cat`

<img src="assets/13. Intro Attention/jump.gif" width="500" />    

Neural Network doesn't capture Long term dependencies

## 4 Type if Attention Mechanism
**A.** Simplified Self Attention

**B.** Self Attention:
Trainable weights

**C.** Casual Attention: 
Consider previous and current inputs

**D.** Multi-Head Attention: 
Enable to simultaneously attend to information from different reprsentation subspace.

## History
### Problem withh modelling long sequence
<img src="assets/13. Intro Attention/trans.png" width="500" />    

`
Eg: Harry Potter went to station number 93 by 4 ....
`  
We need `memory` yo know station number

To address this issue Encoder and Decoder was introduced

`Encoder`: Receive and Read german text and pass to decoder
`Decoder`: Translate to English Text

<img src="assets/13. Intro Attention/im.gif" width="500" />    

`Fig :Encoder get german language and converts to **context vector** which contains meaning then sends to decoder. Decoder generate output`
  
  
  
>Before Transformer, **RNN** were most popular encoder-decoder architecture for language translation.

**Encoder Decoder in RNN**

Input Text -> Encode Text -> Update `Hidden State` at each step -> Final `Hidden State`
<img src="assets/13. Intro Attention/endec.png" width="500" />    

Why do we need attention then?
Decoder have only access to final hidden state in RNN. 

It is tough for only one hidden state to have entire information

### 2014 Bahdanau Attention Mechanism
[Source]()


Modifies the encoder- decoder RNN such that the decoder can selectively access different parts of the input sequence at each decoding step.
Access to all input words and allow how much importance to make.

Imoprtance is determined by `attention weight`

<img src="assets/13. Intro Attention/attwt.png" width="500" />    

Some input token are more important then other for generating a given output token

This importance is determined by the so called `attention weight`.

### 2017 Attention is all you Need
Researchers found that RNN architecture are not required for building deep neural network for natural language processing and proposed the original transformer architecture.

- With `self attention mechanism` inspired by Bahdhanau Attention Mechanism.

Attention Mechanism:
- `Dynamic Focus`(Selectively select which word to given more focus)

1980: RNN
- Feature: Hidden Layer
- Problem : 
Vanishing Gradient

1997: LSMT
- Problem : 
Long Term COntext

2014: Attention
- Feature: Which inofrmation to give more attention.

2017: Transformer
- Self Attention: Allow each position of input sequence to attens to all position in same sequnence.

<img src="assets/13. Intro Attention/att.png" width="500" />    
