# Input Target Pair
The last step before we create `vector embedding` is to create `input target pair`.

What do these input target pairs look like?

<img src="assets/9. Input Target Pairs/inp.png" width="500" />  

`Blue`: Input  
`Red`: Output

- Self-Supervised Learning | Auto-Regressive

## Summary
- Given text sample: Extracting `Input block`. &   
`LLM prediction task` during training is to `predict the next word` that follow input block.  
During training we mask out all words that are past the target

## Process 
- Create 2 variables `x` and `y`
- `x` contain input token and 
- `y` contain target (input shifted by one)

### Eg:
X=[1,2,3,4]  
y=[2,3,4,5]

### Context Size
How many word to be given to model for prediction; in notebook 4
- In LLM number of prediction task is as set in context_size

## Implementing into Dataloader
We need to convert it into PyTorch tensors.  
We will implement a data loader that fetches input-output target pairs using a sliding window approach.

<img src="assets/9. Input Target Pairs/dataloader.png" width="500" />  

To implement efficient dataloader, we collect inputs in a tensor x, where each row represent one input context. The second tensor y contains the corresponding prediction targets (next words), which are created by shifting the input by one position.

#### Steps: 
1. Initialize tokenizer
2. Create Dataset
3. drop_true= True
    To drop the last batch if it is shorter than the specified batch_size to prevent loss spikes during training.
4. The number of CPU processes to use for preprocessing  


- `Batch size`= Number of batches model process at once before updating parameter
- `num_workers`= For parallel processing

### Stride
<img src="assets/9. Input Target Pairs/stride.png" width="500" />  

- `Stride`: Gap of word between input of different batches
- More stride prevent repetead data feeding for training and prevent overfitting.
- We usually put `stride length`=`context length` inorder not to miss any word.